{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0dab5406",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-15T01:30:11.617119Z",
     "iopub.status.busy": "2025-04-15T01:30:11.616741Z",
     "iopub.status.idle": "2025-04-15T01:30:11.635117Z",
     "shell.execute_reply": "2025-04-15T01:30:11.633924Z"
    },
    "papermill": {
     "duration": 0.025617,
     "end_time": "2025-04-15T01:30:11.637073",
     "exception": false,
     "start_time": "2025-04-15T01:30:11.611456",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/newdataset/vk.mp3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7de8ff",
   "metadata": {
    "papermill": {
     "duration": 0.004311,
     "end_time": "2025-04-15T01:30:11.647111",
     "exception": false,
     "start_time": "2025-04-15T01:30:11.642800",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## ⚙️ Install Required Libraries\n",
    "\n",
    "This installs `whisper`, `google-generativeai`, and [langgraph](https://www.langgraph.dev/) — a library for building multi-step AI workflows.  \n",
    "Run this cell only once per session.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5485466",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T01:30:11.657109Z",
     "iopub.status.busy": "2025-04-15T01:30:11.656766Z",
     "iopub.status.idle": "2025-04-15T01:31:50.515878Z",
     "shell.execute_reply": "2025-04-15T01:31:50.514824Z"
    },
    "papermill": {
     "duration": 98.866106,
     "end_time": "2025-04-15T01:31:50.517530",
     "exception": false,
     "start_time": "2025-04-15T01:30:11.651424",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.5/800.5 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.0/145.0 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m70.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.6/223.6 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "pylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Install dependencies (run only once)\n",
    "!pip install -q openai-whisper google-generativeai langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92d4b432",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T01:31:50.570600Z",
     "iopub.status.busy": "2025-04-15T01:31:50.570272Z",
     "iopub.status.idle": "2025-04-15T01:32:01.115290Z",
     "shell.execute_reply": "2025-04-15T01:32:01.114165Z"
    },
    "papermill": {
     "duration": 10.573629,
     "end_time": "2025-04-15T01:32:01.117086",
     "exception": false,
     "start_time": "2025-04-15T01:31:50.543457",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.7/144.7 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.9/100.9 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "jupyterlab-lsp 3.10.2 requires jupyterlab<4.0.0a0,>=3.1.0, which is not installed.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip uninstall -qqy jupyterlab  # Remove unused conflicting packages\n",
    "!pip install -U -q \"google-genai==1.7.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54bfc32a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T01:32:01.223342Z",
     "iopub.status.busy": "2025-04-15T01:32:01.222980Z",
     "iopub.status.idle": "2025-04-15T01:33:14.819188Z",
     "shell.execute_reply": "2025-04-15T01:33:14.818048Z"
    },
    "papermill": {
     "duration": 73.626306,
     "end_time": "2025-04-15T01:33:14.821477",
     "exception": false,
     "start_time": "2025-04-15T01:32:01.195171",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting TTS\r\n",
      "  Downloading TTS-0.22.0-cp311-cp311-manylinux1_x86_64.whl.metadata (21 kB)\r\n",
      "Requirement already satisfied: cython>=0.29.30 in /usr/local/lib/python3.11/dist-packages (from TTS) (3.0.12)\r\n",
      "Requirement already satisfied: scipy>=1.11.2 in /usr/local/lib/python3.11/dist-packages (from TTS) (1.15.2)\r\n",
      "Requirement already satisfied: torch>=2.1 in /usr/local/lib/python3.11/dist-packages (from TTS) (2.5.1+cu124)\r\n",
      "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (from TTS) (2.5.1+cu124)\r\n",
      "Requirement already satisfied: soundfile>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from TTS) (0.13.1)\r\n",
      "Requirement already satisfied: librosa>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from TTS) (0.10.2.post1)\r\n",
      "Collecting scikit-learn>=1.3.0 (from TTS)\r\n",
      "  Downloading scikit_learn-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\r\n",
      "Requirement already satisfied: inflect>=5.6.0 in /usr/local/lib/python3.11/dist-packages (from TTS) (7.5.0)\r\n",
      "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.11/dist-packages (from TTS) (4.67.1)\r\n",
      "Collecting anyascii>=0.3.0 (from TTS)\r\n",
      "  Downloading anyascii-0.3.2-py3-none-any.whl.metadata (1.5 kB)\r\n",
      "Requirement already satisfied: pyyaml>=6.0 in /usr/local/lib/python3.11/dist-packages (from TTS) (6.0.2)\r\n",
      "Requirement already satisfied: fsspec>=2023.6.0 in /usr/local/lib/python3.11/dist-packages (from TTS) (2025.3.2)\r\n",
      "Requirement already satisfied: aiohttp>=3.8.1 in /usr/local/lib/python3.11/dist-packages (from TTS) (3.11.16)\r\n",
      "Requirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.11/dist-packages (from TTS) (24.2)\r\n",
      "Requirement already satisfied: flask>=2.0.1 in /usr/local/lib/python3.11/dist-packages (from TTS) (3.1.0)\r\n",
      "Collecting pysbd>=0.3.4 (from TTS)\r\n",
      "  Downloading pysbd-0.3.4-py3-none-any.whl.metadata (6.1 kB)\r\n",
      "Collecting umap-learn>=0.5.1 (from TTS)\r\n",
      "  Downloading umap_learn-0.5.7-py3-none-any.whl.metadata (21 kB)\r\n",
      "Collecting pandas<2.0,>=1.4 (from TTS)\r\n",
      "  Downloading pandas-1.5.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\r\n",
      "Requirement already satisfied: matplotlib>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from TTS) (3.7.5)\r\n",
      "Collecting trainer>=0.0.32 (from TTS)\r\n",
      "  Downloading trainer-0.0.36-py3-none-any.whl.metadata (8.1 kB)\r\n",
      "Collecting coqpit>=0.0.16 (from TTS)\r\n",
      "  Downloading coqpit-0.0.17-py3-none-any.whl.metadata (11 kB)\r\n",
      "Requirement already satisfied: jieba in /usr/local/lib/python3.11/dist-packages (from TTS) (0.42.1)\r\n",
      "Collecting pypinyin (from TTS)\r\n",
      "  Downloading pypinyin-0.54.0-py2.py3-none-any.whl.metadata (12 kB)\r\n",
      "Collecting hangul-romanize (from TTS)\r\n",
      "  Downloading hangul_romanize-0.1.0-py3-none-any.whl.metadata (1.2 kB)\r\n",
      "Collecting gruut==2.2.3 (from gruut[de,es,fr]==2.2.3->TTS)\r\n",
      "  Downloading gruut-2.2.3.tar.gz (73 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Collecting jamo (from TTS)\r\n",
      "  Downloading jamo-0.4.1-py3-none-any.whl.metadata (2.3 kB)\r\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from TTS) (3.9.1)\r\n",
      "Collecting g2pkk>=0.1.1 (from TTS)\r\n",
      "  Downloading g2pkk-0.1.2-py3-none-any.whl.metadata (2.0 kB)\r\n",
      "Collecting bangla (from TTS)\r\n",
      "  Downloading bangla-0.0.2-py2.py3-none-any.whl.metadata (4.5 kB)\r\n",
      "Collecting bnnumerizer (from TTS)\r\n",
      "  Downloading bnnumerizer-0.0.2.tar.gz (4.7 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Collecting bnunicodenormalizer (from TTS)\r\n",
      "  Downloading bnunicodenormalizer-0.1.7-py3-none-any.whl.metadata (22 kB)\r\n",
      "Requirement already satisfied: einops>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from TTS) (0.8.1)\r\n",
      "Requirement already satisfied: transformers>=4.33.0 in /usr/local/lib/python3.11/dist-packages (from TTS) (4.51.1)\r\n",
      "Collecting encodec>=0.1.1 (from TTS)\r\n",
      "  Downloading encodec-0.1.1.tar.gz (3.7 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Collecting unidecode>=1.3.2 (from TTS)\r\n",
      "  Downloading Unidecode-1.3.8-py3-none-any.whl.metadata (13 kB)\r\n",
      "Collecting num2words (from TTS)\r\n",
      "  Downloading num2words-0.5.14-py3-none-any.whl.metadata (13 kB)\r\n",
      "Requirement already satisfied: spacy>=3 in /usr/local/lib/python3.11/dist-packages (from spacy[ja]>=3->TTS) (3.7.5)\r\n",
      "Requirement already satisfied: numpy>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from TTS) (1.26.4)\r\n",
      "Requirement already satisfied: numba>=0.57.0 in /usr/local/lib/python3.11/dist-packages (from TTS) (0.60.0)\r\n",
      "Requirement already satisfied: Babel<3.0.0,>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS) (2.17.0)\r\n",
      "Collecting dateparser~=1.1.0 (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS)\r\n",
      "  Downloading dateparser-1.1.8-py2.py3-none-any.whl.metadata (27 kB)\r\n",
      "Collecting gruut-ipa<1.0,>=0.12.0 (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS)\r\n",
      "  Downloading gruut-ipa-0.13.0.tar.gz (101 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Collecting gruut_lang_en~=2.0.0 (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS)\r\n",
      "  Downloading gruut_lang_en-2.0.1.tar.gz (15.3 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.3/15.3 MB\u001b[0m \u001b[31m77.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Collecting jsonlines~=1.2.0 (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS)\r\n",
      "  Downloading jsonlines-1.2.0-py2.py3-none-any.whl.metadata (1.3 kB)\r\n",
      "Collecting networkx<3.0.0,>=2.5.0 (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS)\r\n",
      "  Downloading networkx-2.8.8-py3-none-any.whl.metadata (5.1 kB)\r\n",
      "Collecting python-crfsuite~=0.9.7 (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS)\r\n",
      "  Downloading python_crfsuite-0.9.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\r\n",
      "Collecting gruut_lang_de~=2.0.0 (from gruut[de,es,fr]==2.2.3->TTS)\r\n",
      "  Downloading gruut_lang_de-2.0.1.tar.gz (18.1 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m80.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Collecting gruut_lang_es~=2.0.0 (from gruut[de,es,fr]==2.2.3->TTS)\r\n",
      "  Downloading gruut_lang_es-2.0.1.tar.gz (31.4 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Collecting gruut_lang_fr~=2.0.0 (from gruut[de,es,fr]==2.2.3->TTS)\r\n",
      "  Downloading gruut_lang_fr-2.0.2.tar.gz (10.9 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m87.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.1->TTS) (2.6.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.1->TTS) (1.3.2)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.1->TTS) (25.3.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.1->TTS) (1.5.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.1->TTS) (6.2.0)\r\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.1->TTS) (0.3.1)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.1->TTS) (1.19.0)\r\n",
      "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from flask>=2.0.1->TTS) (3.1.3)\r\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask>=2.0.1->TTS) (3.1.6)\r\n",
      "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from flask>=2.0.1->TTS) (2.2.0)\r\n",
      "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask>=2.0.1->TTS) (8.1.8)\r\n",
      "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from flask>=2.0.1->TTS) (1.9.0)\r\n",
      "Requirement already satisfied: more_itertools>=8.5.0 in /usr/local/lib/python3.11/dist-packages (from inflect>=5.6.0->TTS) (10.6.0)\r\n",
      "Requirement already satisfied: typeguard>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from inflect>=5.6.0->TTS) (4.4.1)\r\n",
      "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.0->TTS) (3.0.1)\r\n",
      "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.0->TTS) (1.4.2)\r\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.0->TTS) (4.4.2)\r\n",
      "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.0->TTS) (1.8.2)\r\n",
      "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.0->TTS) (0.5.0.post1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.0->TTS) (4.13.1)\r\n",
      "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.0->TTS) (0.4)\r\n",
      "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.0->TTS) (1.1.0)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->TTS) (1.3.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->TTS) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->TTS) (4.56.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->TTS) (1.4.8)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->TTS) (11.1.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->TTS) (3.2.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->TTS) (2.9.0.post0)\r\n",
      "Collecting docopt>=0.6.2 (from num2words->TTS)\r\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.57.0->TTS) (0.43.0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.3->TTS) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.3->TTS) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.3->TTS) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.3->TTS) (2025.1.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.3->TTS) (2022.1.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.3->TTS) (2.4.1)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<2.0,>=1.4->TTS) (2025.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.3.0->TTS) (3.6.0)\r\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.0->TTS) (1.17.1)\r\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (3.0.12)\r\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (1.0.5)\r\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (1.0.12)\r\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (2.0.11)\r\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (3.0.9)\r\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (8.2.5)\r\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (1.1.3)\r\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (2.5.1)\r\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (2.0.10)\r\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (0.4.1)\r\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (0.15.1)\r\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (2.32.3)\r\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (2.11.3)\r\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (75.1.0)\r\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (3.5.0)\r\n",
      "Collecting sudachipy!=0.6.1,>=0.5.2 (from spacy[ja]>=3->TTS)\r\n",
      "  Downloading SudachiPy-0.6.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\r\n",
      "Collecting sudachidict-core>=20211220 (from spacy[ja]>=3->TTS)\r\n",
      "  Downloading SudachiDict_core-20250129-py3-none-any.whl.metadata (2.5 kB)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (3.18.0)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (9.1.0.70)\r\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (12.4.5.8)\r\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (11.2.1.3)\r\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (10.3.5.147)\r\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (11.6.1.9)\r\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (12.3.1.170)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (2.21.5)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (12.4.127)\r\n",
      "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (3.1.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.1->TTS) (1.3.0)\r\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from trainer>=0.0.32->TTS) (7.0.0)\r\n",
      "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (from trainer>=0.0.32->TTS) (2.18.0)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.33.0->TTS) (0.30.2)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.33.0->TTS) (2024.11.6)\r\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.33.0->TTS) (0.21.0)\r\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.33.0->TTS) (0.5.2)\r\n",
      "Collecting pynndescent>=0.5 (from umap-learn>=0.5.1->TTS)\r\n",
      "  Downloading pynndescent-0.5.13-py3-none-any.whl.metadata (6.8 kB)\r\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.0->TTS) (2.22)\r\n",
      "Requirement already satisfied: tzlocal in /usr/local/lib/python3.11/dist-packages (from dateparser~=1.1.0->gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS) (5.3)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1.2->flask>=2.0.1->TTS) (3.0.2)\r\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from jsonlines~=1.2.0->gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS) (1.17.0)\r\n",
      "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy>=3->spacy[ja]>=3->TTS) (1.3.0)\r\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa>=0.10.0->TTS) (4.3.7)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3->spacy[ja]>=3->TTS) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3->spacy[ja]>=3->TTS) (2.33.1)\r\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3->spacy[ja]>=3->TTS) (0.4.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3->spacy[ja]>=3->TTS) (3.4.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3->spacy[ja]>=3->TTS) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3->spacy[ja]>=3->TTS) (2.3.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3->spacy[ja]>=3->TTS) (2025.1.31)\r\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy>=3->spacy[ja]>=3->TTS) (0.7.11)\r\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy>=3->spacy[ja]>=3->TTS) (0.1.5)\r\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->TTS) (1.5.4)\r\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->TTS) (14.0.0)\r\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy>=3->spacy[ja]>=3->TTS) (0.20.0)\r\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy>=3->spacy[ja]>=3->TTS) (7.1.0)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.24.3->TTS) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.24.3->TTS) (2022.1.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.24.3->TTS) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.24.3->TTS) (2024.2.0)\r\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard->trainer>=0.0.32->TTS) (1.4.0)\r\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard->trainer>=0.0.32->TTS) (1.70.0)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard->trainer>=0.0.32->TTS) (3.7)\r\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard->trainer>=0.0.32->TTS) (3.20.3)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->trainer>=0.0.32->TTS) (0.7.2)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.24.3->TTS) (2024.2.0)\r\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy>=3->spacy[ja]>=3->TTS) (1.2.1)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->TTS) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->TTS) (2.19.1)\r\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy>=3->spacy[ja]>=3->TTS) (1.17.2)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->TTS) (0.1.2)\r\n",
      "Downloading TTS-0.22.0-cp311-cp311-manylinux1_x86_64.whl (937 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m938.0/938.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading anyascii-0.3.2-py3-none-any.whl (289 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading coqpit-0.0.17-py3-none-any.whl (13 kB)\r\n",
      "Downloading g2pkk-0.1.2-py3-none-any.whl (25 kB)\r\n",
      "Downloading num2words-0.5.14-py3-none-any.whl (163 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.5/163.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pandas-1.5.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m86.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pysbd-0.3.4-py3-none-any.whl (71 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading scikit_learn-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m91.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading trainer-0.0.36-py3-none-any.whl (51 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.2/51.2 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading umap_learn-0.5.7-py3-none-any.whl (88 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.8/88.8 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading Unidecode-1.3.8-py3-none-any.whl (235 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading bangla-0.0.2-py2.py3-none-any.whl (6.2 kB)\r\n",
      "Downloading bnunicodenormalizer-0.1.7-py3-none-any.whl (23 kB)\r\n",
      "Downloading hangul_romanize-0.1.0-py3-none-any.whl (4.6 kB)\r\n",
      "Downloading jamo-0.4.1-py3-none-any.whl (9.5 kB)\r\n",
      "Downloading pypinyin-0.54.0-py2.py3-none-any.whl (837 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m837.0/837.0 kB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading dateparser-1.1.8-py2.py3-none-any.whl (293 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.8/293.8 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading jsonlines-1.2.0-py2.py3-none-any.whl (7.6 kB)\r\n",
      "Downloading networkx-2.8.8-py3-none-any.whl (2.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pynndescent-0.5.13-py3-none-any.whl (56 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading python_crfsuite-0.9.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading SudachiDict_core-20250129-py3-none-any.whl (72.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.1/72.1 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading SudachiPy-0.6.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hBuilding wheels for collected packages: gruut, encodec, bnnumerizer, docopt, gruut-ipa, gruut_lang_de, gruut_lang_en, gruut_lang_es, gruut_lang_fr\r\n",
      "  Building wheel for gruut (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for gruut: filename=gruut-2.2.3-py3-none-any.whl size=75788 sha256=711505083aa659368044e39653998ec580d6e353aaaa6c87c691f9282806eb3c\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/1f/a0/bc/4dacab52579ab464cffafbe7a8e3792dd36ad9ac288b264843\r\n",
      "  Building wheel for encodec (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for encodec: filename=encodec-0.1.1-py3-none-any.whl size=45760 sha256=f825ecd27250d5065115f538984cc39c6e150035d728c7eaf2eae10219d590e2\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/b4/a4/88/480018a664e58ca7ce6708759193ee51b017b3b72aa3df8a85\r\n",
      "  Building wheel for bnnumerizer (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for bnnumerizer: filename=bnnumerizer-0.0.2-py3-none-any.whl size=5261 sha256=4eccbea928a03e7f0f14a628f3856bc7406e22df37cde4c67a074c476007bac7\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/9e/b9/e3/4145416693824818c0b931988a692676ecd4bbf2ea41d1eedd\r\n",
      "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=496e9ed73643653a435d5fbeb0939f29bd3f25a924916b605b18a845568aba75\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/1a/b0/8c/4b75c4116c31f83c8f9f047231251e13cc74481cca4a78a9ce\r\n",
      "  Building wheel for gruut-ipa (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for gruut-ipa: filename=gruut_ipa-0.13.0-py3-none-any.whl size=104873 sha256=299bc4226d7dd0c43505405433bfb66360fe27fcf9aa79be140f6b789cf94b70\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/c7/10/89/a5908dd7a9a032229684b7679396785e19f816667f788087fb\r\n",
      "  Building wheel for gruut_lang_de (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for gruut_lang_de: filename=gruut_lang_de-2.0.1-py3-none-any.whl size=18498313 sha256=256676ff8aa4b632c90f90702419ad058d7f96530561063e4e2e2dc8188db53e\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/87/fa/df/5fdf5d3cc26ba859b8698a1f28581d1a6aa081edc6df9847ab\r\n",
      "  Building wheel for gruut_lang_en (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for gruut_lang_en: filename=gruut_lang_en-2.0.1-py3-none-any.whl size=15326857 sha256=f6387be4a762d038752174f7b67895e694b5568219d782651075c0220b60d2b3\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/06/30/52/dc5cd222b4bbde285838fed1f96636e96f85cd75493e79a978\r\n",
      "  Building wheel for gruut_lang_es (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for gruut_lang_es: filename=gruut_lang_es-2.0.1-py3-none-any.whl size=32173928 sha256=da86d34e1c9aec47b9ce10751b931f3c0aa5fcf68dc582dc248cb437f6b0c2dd\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/c8/eb/59/30b5d15e56347e595f613036cbea0f807ad9621c75cd75d912\r\n",
      "  Building wheel for gruut_lang_fr (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for gruut_lang_fr: filename=gruut_lang_fr-2.0.2-py3-none-any.whl size=10968766 sha256=d59a42320248d16a9007de48d77b4437e25d8dea7c9816d65a3e17572805494f\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/e0/e7/a0/7c416a3eeaa94ca71bf7bcbc6289cced2263d8ba35e82444bb\r\n",
      "Successfully built gruut encodec bnnumerizer docopt gruut-ipa gruut_lang_de gruut_lang_en gruut_lang_es gruut_lang_fr\r\n",
      "Installing collected packages: sudachipy, jamo, hangul-romanize, gruut_lang_fr, gruut_lang_es, gruut_lang_en, gruut_lang_de, docopt, bnunicodenormalizer, bnnumerizer, bangla, unidecode, sudachidict-core, python-crfsuite, pysbd, pypinyin, num2words, networkx, jsonlines, gruut-ipa, coqpit, anyascii, g2pkk, dateparser, scikit-learn, pynndescent, gruut, umap-learn, trainer, pandas, encodec, TTS\r\n",
      "  Attempting uninstall: networkx\r\n",
      "    Found existing installation: networkx 3.4.2\r\n",
      "    Uninstalling networkx-3.4.2:\r\n",
      "      Successfully uninstalled networkx-3.4.2\r\n",
      "  Attempting uninstall: scikit-learn\r\n",
      "    Found existing installation: scikit-learn 1.2.2\r\n",
      "    Uninstalling scikit-learn-1.2.2:\r\n",
      "      Successfully uninstalled scikit-learn-1.2.2\r\n",
      "  Attempting uninstall: pandas\r\n",
      "    Found existing installation: pandas 2.2.3\r\n",
      "    Uninstalling pandas-2.2.3:\r\n",
      "      Successfully uninstalled pandas-2.2.3\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "dask-cudf-cu12 25.2.2 requires pandas<2.2.4dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\r\n",
      "dask-expr 1.1.21 requires pandas>=2, but you have pandas 1.5.3 which is incompatible.\r\n",
      "cudf-cu12 25.2.2 requires pandas<2.2.4dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\r\n",
      "category-encoders 2.7.0 requires scikit-learn<1.6.0,>=1.0.0, but you have scikit-learn 1.6.1 which is incompatible.\r\n",
      "datasets 3.5.0 requires fsspec[http]<=2024.12.0,>=2023.1.0, but you have fsspec 2025.3.2 which is incompatible.\r\n",
      "woodwork 0.31.0 requires pandas>=2.0.0, but you have pandas 1.5.3 which is incompatible.\r\n",
      "featuretools 1.31.0 requires pandas>=2.0.0, but you have pandas 1.5.3 which is incompatible.\r\n",
      "visions 0.8.1 requires pandas>=2.0.0, but you have pandas 1.5.3 which is incompatible.\r\n",
      "pyldavis 3.4.1 requires pandas>=2.0.0, but you have pandas 1.5.3 which is incompatible.\r\n",
      "nilearn 0.11.1 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\r\n",
      "google-colab 1.0.0 requires notebook==6.5.5, but you have notebook 6.5.4 which is incompatible.\r\n",
      "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 1.5.3 which is incompatible.\r\n",
      "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\r\n",
      "nx-cugraph-cu12 24.12.0 requires networkx>=3.2, but you have networkx 2.8.8 which is incompatible.\r\n",
      "scikit-image 0.25.1 requires networkx>=3.0, but you have networkx 2.8.8 which is incompatible.\r\n",
      "pandas-gbq 0.26.1 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "bigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\r\n",
      "ibis-framework 9.2.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\r\n",
      "ibis-framework 9.2.0 requires toolz<1,>=0.11, but you have toolz 1.0.0 which is incompatible.\r\n",
      "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.5 which is incompatible.\r\n",
      "plotnine 0.14.5 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\r\n",
      "xarray 2025.1.2 requires pandas>=2.1, but you have pandas 1.5.3 which is incompatible.\r\n",
      "mizani 0.13.1 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed TTS-0.22.0 anyascii-0.3.2 bangla-0.0.2 bnnumerizer-0.0.2 bnunicodenormalizer-0.1.7 coqpit-0.0.17 dateparser-1.1.8 docopt-0.6.2 encodec-0.1.1 g2pkk-0.1.2 gruut-2.2.3 gruut-ipa-0.13.0 gruut_lang_de-2.0.1 gruut_lang_en-2.0.1 gruut_lang_es-2.0.1 gruut_lang_fr-2.0.2 hangul-romanize-0.1.0 jamo-0.4.1 jsonlines-1.2.0 networkx-2.8.8 num2words-0.5.14 pandas-1.5.3 pynndescent-0.5.13 pypinyin-0.54.0 pysbd-0.3.4 python-crfsuite-0.9.11 scikit-learn-1.6.1 sudachidict-core-20250129 sudachipy-0.6.10 trainer-0.0.36 umap-learn-0.5.7 unidecode-1.3.8\r\n"
     ]
    }
   ],
   "source": [
    "!pip install TTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e55a6eb",
   "metadata": {
    "papermill": {
     "duration": 0.035522,
     "end_time": "2025-04-15T01:33:14.895727",
     "exception": false,
     "start_time": "2025-04-15T01:33:14.860205",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 📦 Import Libraries & Setup Gemini Model\n",
    "\n",
    "Imports `whisper` for speech-to-text, `genai` for Gemini, and `langgraph` for workflow logic.  \n",
    "Initializes Gemini 1.5 Pro for AI content generation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5feb1bc2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T01:33:15.039617Z",
     "iopub.status.busy": "2025-04-15T01:33:15.039176Z",
     "iopub.status.idle": "2025-04-15T01:33:24.722348Z",
     "shell.execute_reply": "2025-04-15T01:33:24.721351Z"
    },
    "papermill": {
     "duration": 9.722415,
     "end_time": "2025-04-15T01:33:24.724064",
     "exception": false,
     "start_time": "2025-04-15T01:33:15.001649",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import whisper\n",
    "import google.generativeai as genai\n",
    "from langgraph.graph import StateGraph, END\n",
    "import json\n",
    "import os\n",
    "\n",
    "gemini_model = genai.GenerativeModel('gemini-1.5-pro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "330d36df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T01:33:24.796585Z",
     "iopub.status.busy": "2025-04-15T01:33:24.796111Z",
     "iopub.status.idle": "2025-04-15T01:33:25.391660Z",
     "shell.execute_reply": "2025-04-15T01:33:25.390696Z"
    },
    "papermill": {
     "duration": 0.634221,
     "end_time": "2025-04-15T01:33:25.393333",
     "exception": false,
     "start_time": "2025-04-15T01:33:24.759112",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.7.0'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "genai.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "863896ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T01:33:25.538066Z",
     "iopub.status.busy": "2025-04-15T01:33:25.537695Z",
     "iopub.status.idle": "2025-04-15T01:33:25.707272Z",
     "shell.execute_reply": "2025-04-15T01:33:25.706329Z"
    },
    "papermill": {
     "duration": 0.2094,
     "end_time": "2025-04-15T01:33:25.709130",
     "exception": false,
     "start_time": "2025-04-15T01:33:25.499730",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from kaggle_secrets import UserSecretsClient\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Load API key from Kaggle secrets\n",
    "GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n",
    "\n",
    "# Configure Gemini client\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e08f3c9",
   "metadata": {
    "papermill": {
     "duration": 0.036828,
     "end_time": "2025-04-15T01:33:25.852449",
     "exception": false,
     "start_time": "2025-04-15T01:33:25.815621",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 🧠 Load Whisper ASR Model\n",
    "\n",
    "This loads the `\"small\"` Whisper model by OpenAI for converting audio to text.  \n",
    "🔗 [Whisper GitHub](https://github.com/openai/whisper) | Great for speech recognition tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "964bf31f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T01:33:25.925264Z",
     "iopub.status.busy": "2025-04-15T01:33:25.924292Z",
     "iopub.status.idle": "2025-04-15T01:33:46.222062Z",
     "shell.execute_reply": "2025-04-15T01:33:46.221191Z"
    },
    "papermill": {
     "duration": 20.335326,
     "end_time": "2025-04-15T01:33:46.223615",
     "exception": false,
     "start_time": "2025-04-15T01:33:25.888289",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 461M/461M [00:14<00:00, 33.1MiB/s]\n",
      "/usr/local/lib/python3.11/dist-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "# Load Whisper ASR (Automatic Speech Recognition) model\n",
    "whisper_model = whisper.load_model(\"small\")\n",
    "\n",
    "def transcribe_audio(audio_file_path):\n",
    "    result = whisper_model.transcribe(audio_file_path)\n",
    "    text = result[\"text\"]\n",
    "    print(text)  # <-- print inside the function\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc89e732",
   "metadata": {
    "papermill": {
     "duration": 0.042598,
     "end_time": "2025-04-15T01:33:46.308530",
     "exception": false,
     "start_time": "2025-04-15T01:33:46.265932",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##  Few-Shot Grammar Correction Examples\n",
    "\n",
    "Provides sample input-output pairs to guide Gemini in correcting grammar.  \n",
    "Helps the model understand the expected correction format for similar sentences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96329974",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T01:33:46.392231Z",
     "iopub.status.busy": "2025-04-15T01:33:46.391870Z",
     "iopub.status.idle": "2025-04-15T01:33:46.397014Z",
     "shell.execute_reply": "2025-04-15T01:33:46.396017Z"
    },
    "papermill": {
     "duration": 0.049099,
     "end_time": "2025-04-15T01:33:46.398727",
     "exception": false,
     "start_time": "2025-04-15T01:33:46.349628",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Few-shot examples for better corrections\n",
    "few_shot_examples = \"\"\"\n",
    "Example 1:\n",
    "User: i am working in Google\n",
    "Response: {\"original\": \"i am working in Google\", \"corrected\": \"I am working at Google.\"}\n",
    "\n",
    "Example 2:\n",
    "User: she go to school every day\n",
    "Response: {\"original\": \"she go to school every day\", \"corrected\": \"She goes to school every day.\"}\n",
    "\n",
    "Example 3:\n",
    "User: they is playing outside\n",
    "Response: {\"original\": \"they is playing outside\", \"corrected\": \"They are playing outside.\"}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfb826d",
   "metadata": {
    "papermill": {
     "duration": 0.042319,
     "end_time": "2025-04-15T01:33:46.482873",
     "exception": false,
     "start_time": "2025-04-15T01:33:46.440554",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 🤖 Correct Grammar Using Gemini with JSON Output\n",
    "\n",
    "This function sends a prompt to [Gemini 1.5 Pro](https://ai.google.dev/) to fix grammar mistakes in a sentence.  \n",
    "It uses few-shot examples to help Gemini understand the correction style.  \n",
    "The model's response is expected in structured JSON like `{\"original\": ..., \"corrected\": ...}`.  \n",
    "If the output isn't valid JSON, it gracefully falls back to a default format.  \n",
    "This ensures consistent and clean correction results that can be easily parsed and reused.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6749504",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T01:33:46.567482Z",
     "iopub.status.busy": "2025-04-15T01:33:46.567146Z",
     "iopub.status.idle": "2025-04-15T01:33:46.572673Z",
     "shell.execute_reply": "2025-04-15T01:33:46.571762Z"
    },
    "papermill": {
     "duration": 0.048896,
     "end_time": "2025-04-15T01:33:46.574158",
     "exception": false,
     "start_time": "2025-04-15T01:33:46.525262",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Correct text using Gemini and structured JSON output\n",
    "def correct_text_with_gemini(text):\n",
    "    prompt = f\"\"\"\n",
    "You are an expert English grammar corrector. Always respond with a valid JSON object.\n",
    "\n",
    "{few_shot_examples}\n",
    "\n",
    "Now correct this sentence:\n",
    "User: {text}\n",
    "Response:\n",
    "\"\"\"\n",
    "    response = gemini_model.generate_content(prompt)\n",
    "\n",
    "    try:\n",
    "        # Ensure valid JSON format\n",
    "        correction_json = json.loads(response.text)\n",
    "    except json.JSONDecodeError:\n",
    "        correction_json = {\"original\": text, \"corrected\": response.text.strip()}\n",
    "\n",
    "    return correction_json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9207146a",
   "metadata": {
    "papermill": {
     "duration": 0.041228,
     "end_time": "2025-04-15T01:33:46.657210",
     "exception": false,
     "start_time": "2025-04-15T01:33:46.615982",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 🔄 Define LangGraph State and Nodes\n",
    "\n",
    "This code defines a custom state `AudioCorrectionState` using Python's `@dataclass`, which holds:\n",
    "- `audio_path`: the location of the audio file.\n",
    "- `text`: transcribed text from the audio.\n",
    "- `corrected`: dictionary storing both original and corrected sentences.\n",
    "\n",
    "Two **LangGraph nodes** (functions) are defined:\n",
    "- `node_transcribe`: uses Whisper to convert audio into text.\n",
    "- `node_correct`: uses Gemini to fix grammar in the transcribed text.\n",
    "\n",
    "🧠 Learn more about LangGraph stateful workflows:  \n",
    "🔗 [LangGraph GitHub](https://github.com/langchain-ai/langgraph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ac312d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T01:33:46.741931Z",
     "iopub.status.busy": "2025-04-15T01:33:46.741605Z",
     "iopub.status.idle": "2025-04-15T01:33:46.748068Z",
     "shell.execute_reply": "2025-04-15T01:33:46.747172Z"
    },
    "papermill": {
     "duration": 0.050566,
     "end_time": "2025-04-15T01:33:46.749636",
     "exception": false,
     "start_time": "2025-04-15T01:33:46.699070",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the LangGraph State\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class AudioCorrectionState:\n",
    "    audio_path: str = \"\"\n",
    "    text: str = \"\"\n",
    "    corrected: dict = None\n",
    "\n",
    "def node_transcribe(state):\n",
    "    audio_path = state.audio_path   # <-- FIXED\n",
    "    text = transcribe_audio(audio_path)\n",
    "    state.text = text               # <-- FIXED\n",
    "    return state\n",
    "\n",
    "def node_correct(state):\n",
    "    text = state.text               # <-- FIXED\n",
    "    corrected = correct_text_with_gemini(text)\n",
    "    state.corrected = corrected     # <-- FIXED\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15cc3587",
   "metadata": {
    "papermill": {
     "duration": 0.040935,
     "end_time": "2025-04-15T01:33:46.831827",
     "exception": false,
     "start_time": "2025-04-15T01:33:46.790892",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 🧩 Create LangGraph Workflow\n",
    "\n",
    "This builds a **LangGraph workflow** using the `AudioCorrectionState` as the state container.  \n",
    "- `add_node()` adds processing steps (`transcribe` and `correct`) to the graph.  \n",
    "- `set_entry_point(\"transcribe\")` sets the workflow's starting point.  \n",
    "- `add_edge()` defines the execution flow: transcribe ➝ correct ➝ END.  \n",
    "Finally, `graph.compile()` builds the ready-to-run app from this logic.\n",
    "\n",
    "🔗 Learn more at [LangGraph Documentation](https://docs.langgraph.dev/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71b08e62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T01:33:46.918150Z",
     "iopub.status.busy": "2025-04-15T01:33:46.917572Z",
     "iopub.status.idle": "2025-04-15T01:33:46.925482Z",
     "shell.execute_reply": "2025-04-15T01:33:46.924511Z"
    },
    "papermill": {
     "duration": 0.052511,
     "end_time": "2025-04-15T01:33:46.926994",
     "exception": false,
     "start_time": "2025-04-15T01:33:46.874483",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create LangGraph Workflow\n",
    "graph = StateGraph(AudioCorrectionState)\n",
    "graph.add_node(\"transcribe\", node_transcribe)\n",
    "graph.add_node(\"correct\", node_correct)\n",
    "\n",
    "graph.set_entry_point(\"transcribe\")\n",
    "graph.add_edge(\"transcribe\", \"correct\")\n",
    "graph.add_edge(\"correct\", END)\n",
    "\n",
    "app = graph.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68007b38",
   "metadata": {
    "papermill": {
     "duration": 0.042442,
     "end_time": "2025-04-15T01:33:47.010655",
     "exception": false,
     "start_time": "2025-04-15T01:33:46.968213",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 🧠 Step-by-step Audio Correction & Speech Synthesis using Whisper + Gemini + TTS\n",
    "\n",
    "1. **Audio Input**: Load an audio file (e.g., `vk.mp3`) to process.\n",
    "2. **Invoke LangGraph App**: Automatically runs transcription (Whisper) and grammar correction (Gemini 1.5).\n",
    "3. **Extract Corrected Text**: Parse the returned result to fetch only the final corrected sentence.\n",
    "4. **Initialize TTS Model**: Use 🤖 [Coqui TTS](https://github.com/coqui-ai/TTS) to synthesize speech in the original speaker's voice.\n",
    "5. **Speech Generation**: Output corrected audio as `corrected_audio.mp3` using the original speaker's tone (via `speaker_wav`).\n",
    "\n",
    "✅ This creates a full speech-to-corrected-speech loop: **MP3 ➝ Clean Text ➝ Corrected MP3**\n",
    "\n",
    "🔗 TTS Docs: [https://tts.readthedocs.io](https://tts.readthedocs.io)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a11b72cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T01:33:47.098027Z",
     "iopub.status.busy": "2025-04-15T01:33:47.096937Z",
     "iopub.status.idle": "2025-04-15T01:34:44.995877Z",
     "shell.execute_reply": "2025-04-15T01:34:44.994722Z"
    },
    "papermill": {
     "duration": 57.943538,
     "end_time": "2025-04-15T01:34:44.997476",
     "exception": false,
     "start_time": "2025-04-15T01:33:47.053938",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " She go to school every day but not have books. Yesterday he ate apple and drink milk but he don't like it. They was playing in a park but then rains came. I no understand why people is not helps each other. Me very tired because walking too many kilometers.\n",
      "\n",
      "Corrected Text (final to synthesize): She goes to school every day but doesn't have books. Yesterday he ate an apple and drank milk, but he didn't like it. They were playing in a park, but then rain came. I don't understand why people don't help each other. I'm very tired because I walked too many kilometers.\n",
      " > Downloading model to /root/.local/share/tts/tts_models--multilingual--multi-dataset--your_tts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 419M/425M [00:04<00:00, 85.1MiB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Model's license - CC BY-NC-ND 4.0\n",
      " > Check https://creativecommons.org/licenses/by-nc-nd/4.0/ for more info.\n",
      " > Using model: vits\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:16000\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:0\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:None\n",
      " | > fft_size:1024\n",
      " | > power:None\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:None\n",
      " | > signal_norm:None\n",
      " | > symmetric_norm:None\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:None\n",
      " | > pitch_fmin:None\n",
      " | > pitch_fmax:None\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:1.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/TTS/utils/io.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Model fully restored. \n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:16000\n",
      " | > resample:False\n",
      " | > num_mels:64\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:512\n",
      " | > power:1.5\n",
      " | > preemphasis:0.97\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:False\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:False\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:True\n",
      " | > db_level:-27.0\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:160\n",
      " | > win_length:400\n",
      " > External Speaker Encoder Loaded !!\n",
      " > initialization of language-embedding layers.\n",
      " > Model fully restored. \n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:16000\n",
      " | > resample:False\n",
      " | > num_mels:64\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:512\n",
      " | > power:1.5\n",
      " | > preemphasis:0.97\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:False\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:False\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:True\n",
      " | > db_level:-27.0\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:160\n",
      " | > win_length:400\n",
      " > Text splitted to sentences.\n",
      "[\"corrected Text is She goes to school every day but doesn't have books.\", \"Yesterday he ate an apple and drank milk, but he didn't like it.\", 'They were playing in a park, but then rain came.', \"I don't understand why people don't help each other.\", \"I'm very tired because I walked too many kilometers.\"]\n",
      " > Processing time: 7.172138452529907\n",
      " > Real-time factor: 0.3813952912805056\n",
      "\n",
      "✅ Corrected audio saved as corrected_audio.mp3\n"
     ]
    }
   ],
   "source": [
    "from TTS.api import TTS\n",
    "import json\n",
    "import re\n",
    "\n",
    "# Step 1: Audio file path\n",
    "audio_file_path = \"/kaggle/input/newdataset/vk.mp3\"\n",
    "\n",
    "# Step 2: Prepare input\n",
    "inputs = {\n",
    "    \"audio_path\": audio_file_path,\n",
    "}\n",
    "\n",
    "# Step 3: Run transcription and correction\n",
    "result = app.invoke(inputs)\n",
    "\n",
    "# Step 4: Extract corrected text\n",
    "corrected_raw = result['corrected']\n",
    "\n",
    "# Step 5: If corrected_raw is a dict, get 'corrected' field\n",
    "if isinstance(corrected_raw, dict):\n",
    "    corrected_raw = corrected_raw.get(\"corrected\", \"\").strip()\n",
    "else:\n",
    "    raise ValueError(\"Unexpected format: corrected_raw should be a dict!\")\n",
    "\n",
    "# Step 6: Clean up the triple backticks and JSON identifier\n",
    "corrected_raw = corrected_raw.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "\n",
    "# Step 7: Parse it into JSON\n",
    "corrected_dict = json.loads(corrected_raw)\n",
    "\n",
    "# Step 8: Now extract ONLY the 'corrected' text\n",
    "corrected_text = corrected_dict.get(\"corrected\", \"\").strip()\n",
    "\n",
    "# Step 9: Print only corrected sentence\n",
    "print(\"\\nCorrected Text (final to synthesize):\", corrected_text)\n",
    "\n",
    "# Step 10: Prepend a label if needed\n",
    "corrected_text = \"corrected Text is \" + corrected_text\n",
    "\n",
    "# Step 11: Initialize TTS model\n",
    "tts = TTS(model_name=\"tts_models/multilingual/multi-dataset/your_tts\", progress_bar=True, gpu=False)\n",
    "\n",
    "# Step 12: Generate corrected audio\n",
    "if corrected_text:\n",
    "    tts.tts_to_file(\n",
    "        text=corrected_text,\n",
    "        file_path=\"corrected_audio.mp3\",\n",
    "        speaker_wav=audio_file_path,  # Speaker voice sample\n",
    "        language=\"en\"\n",
    "    )\n",
    "    print(\"\\n✅ Corrected audio saved as corrected_audio.mp3\")\n",
    "else:\n",
    "    print(\"\\n⚠️ No corrected text found!\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7127081,
     "sourceId": 11382350,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 281.373392,
   "end_time": "2025-04-15T01:34:47.909728",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-15T01:30:06.536336",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
